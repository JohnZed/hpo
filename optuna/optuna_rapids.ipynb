{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Optuna + RAPIDS\n",
    "\n",
    "Optuna is a lightweight framework for hyperparameter optimization. It provides a code-by-run method which makes it easy to adapt to any already existing code that we have. Just wrapping the objective function with Optuna can help perform a parallel-distributed HPO search over a search space.\n",
    "\n",
    "We'll explore how to use Optuna with RAPIDS and run multi-GPU HPO runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import dask.array as da\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import cuml\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "from cuml.metrics import accuracy_score\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import time\n",
    "\n",
    "@contextmanager\n",
    "def timed(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    t1 = time.time()\n",
    "    print(\"..%-24s:  %8.4f\" % (name, t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 10\n",
    "INPUT_FILE = \"/home/hyperopt/data/air_par.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "from cuml.dask.common import utils as dask_utils\n",
    "\n",
    "# This will use all GPUs on the local host by default\n",
    "cluster = LocalCUDACluster(threads_per_worker=1)\n",
    "c = Client(cluster)\n",
    "\n",
    "# Query the client for all connected workers\n",
    "workers = c.has_what().keys()\n",
    "n_workers = len(workers)\n",
    "n_streams = 8 # Performance optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_parquet(INPUT_FILE)\n",
    "X, y = df.drop([\"ArrDelayBinary\"], axis=1), df[\"ArrDelayBinary\"].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(study):\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the objective Function\n",
    "\n",
    "We will define a objective function for the RandomForestClassifier that searches for max_depth and n_estimators.\n",
    "\n",
    "This will remain constant over different samplers. Samplers are built-in options in Optuna to enable the selection of different sampling algorithms that optuna provides. Some of the available ones include - GridSampler, RandomSampler, TPESampler, etc. We'll try out different samplers and compare their performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Please write actual objective function here.\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 7)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n",
    "\n",
    "    classifier = RandomForestClassifier(max_depth=max_depth,\n",
    "                         n_estimators=n_estimators)\n",
    "\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_valid)\n",
    "    score = accuracy_score(y_valid, y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_study(sampler=optuna.samplers.TPESampler(), study_name=\"Optuna-MultiGPU\"):\n",
    "    with timed(\"multi-gpu\"):\n",
    "        study = optuna.create_study(sampler=sampler,\n",
    "                                    study_name=study_name,\n",
    "                                    storage=\"sqlite:///optuna_mg_db.db\",\n",
    "                                    direction=\"maximize\",\n",
    "                                    load_if_exists=True)\n",
    "        with parallel_backend(\"dask\", n_jobs=n_workers):\n",
    "            study.optimize(objective, n_trials=N_TRIALS, n_jobs=n_workers)\n",
    "    print_results(study)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-24 16:11:11,396] A new study created with name: Optuna-MultiGPU-TPE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..multi-gpu               :   91.3055\n",
      "Number of finished trials:  10\n",
      "Best trial:\n",
      "  Value:  0.8312094211578369\n",
      "  Params: \n",
      "    max_depth: 7\n",
      "    n_estimators: 272\n"
     ]
    }
   ],
   "source": [
    "study_tpe = run_study(optuna.samplers.TPESampler(),study_name=\"Optuna-MultiGPU-TPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-24 16:12:42,729] A new study created with name: Optuna-MultiGPU-CMAE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..multi-gpu               :   88.3086\n",
      "Number of finished trials:  10\n",
      "Best trial:\n",
      "  Value:  0.831394612789154\n",
      "  Params: \n",
      "    max_depth: 7\n",
      "    n_estimators: 130\n"
     ]
    }
   ],
   "source": [
    "study_cmae = run_study(optuna.samplers.CmaEsSampler(), study_name=\"Optuna-MultiGPU-CMAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential calls without Optuna\n",
    "\n",
    "For a comparison let's try sequential calls without Optuna and it's parallel-processing support. We can cleared see that it takes more time to do this. We'll pick the same parameters as Optuna for a fair comparison - these parameters were selected by the sampling algorithm used by Optuna and is available in the `study.trials_dataframe()` for us to pick out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = study_tpe.trials_dataframe()\n",
    "params_max_depth, params_n_estimators = df['params_max_depth'], df['params_n_estimators']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential call function \n",
    "\n",
    "For a cleaner look, let's use a function to perform sequential calls. The function basically sets the parameters to what was passed and trains and evaluates the model and returns the details of the run which can later be used to find the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_call(max_depth, n_estimators):\n",
    "    classifier = RandomForestClassifier(max_depth=max_depth, n_estimators = n_estimators)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_valid)\n",
    "    score = accuracy_score(y_valid, y_pred)\n",
    "    return score, max_depth, n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.8306294083595276, 5, 151), (0.8311144113540649, 7, 272), (0.8308753967285156, 7, 290), (0.8311346173286438, 7, 261), (0.8307803869247437, 6, 309), (0.8307003974914551, 6, 131), (0.8307471871376038, 5, 359), (0.8308507800102234, 6, 141), (0.8308172225952148, 5, 108), (0.8311368227005005, 7, 424)]\n",
      "..no-optuna-call          :   89.2947\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "with timed(\"no-optuna-call\"):\n",
    "    with parallel_backend(\"dask\", n_jobs=n_workers):\n",
    "        results = Parallel()(delayed(seq_call)(max_depth=params_max_depth[i],\n",
    "                     n_estimators=params_n_estimators[i]) for i in range(N_TRIALS))\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Running this without a dask backend is actually faster - takes about 65 seconds to finish by just making N_TRIALS sequential calls. Dask backend makes most sense when used with multi-GPU estimators as we see later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8312597870826721, 7, 424)\n",
      "..no-optuna-no-dask       :   65.9812\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "with timed(\"no-optuna-no-dask\"):\n",
    "    for i in range(N_TRIALS):\n",
    "        results = seq_call(max_depth=params_max_depth[i],\n",
    "                     n_estimators=params_n_estimators[i])\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow callback\n",
    "\n",
    "Optuna supports the integration of various libraries. One of them is a tracking library MLflow, this is used to keep track of the different Hyperopt runs. We can simply add it by adding a callback to a study as shown. \n",
    "\n",
    "Before running the next cell start the mlflow UI by going to the terminal and executing `mlflow ui -p 8004` 8004 is the port we are using here, you can use any port of choice. It defaults to 5000 if the `-p` option is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_callback(study, trial):\n",
    "    trial_value = trial.value if trial.value is not None else float(\"nan\")\n",
    "    with mlflow.start_run(run_name=study.study_name):\n",
    "        mlflow.set_tracking_uri(\"http://127.0.0.1:8004\")\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\"accuracy\": trial_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-24 16:17:55,716] A new study created with name: Optuna-MLflow-callback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..mlflow-callback         :   88.1154\n"
     ]
    }
   ],
   "source": [
    "with timed(\"mlflow-callback\"):\n",
    "    study = optuna.create_study(study_name=\"Optuna-MLflow-callback\",\n",
    "                                storage=\"sqlite:///optuna_mlflow_db.db\",\n",
    "                                direction=\"maximize\",\n",
    "                                load_if_exists=True)\n",
    "    with parallel_backend(\"dask\", n_jobs=n_workers):\n",
    "        study.optimize(objective, n_trials=N_TRIALS, n_jobs=n_workers, timeout=600, callbacks=[mlflow_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU estimators\n",
    "\n",
    "We also have estimators that can run on multiple GPUs. `cuml.dask` has a set of multi-GPU estimators that can run incredibly fast. Let's try that out. In order to do this, we need to used `dask_cudf` dataframes and we will redefine the objective function from earlier to do just that. \n",
    "\n",
    "`objective_mg` converts our split data into dask_cudf dataframes and persists them across all available dask workers. By doing this, we can now run the multi-GPU RandomForestClassifier. Notice that we import the `cuml.dask.ensemble.RandomForestClassifier` for this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.linear_model import LogisticRegression\n",
    "from cuml.dask.ensemble import RandomForestClassifier as dask_RF\n",
    "\n",
    "def objective_mg(trial):\n",
    "    # Please write actual objective function here.\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 7)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n",
    "\n",
    "    import dask_cudf \n",
    "    \n",
    "    classifier = dask_RF(max_depth=max_depth,\n",
    "                         n_estimators=n_estimators)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "\n",
    "    X_train_dask = dask_cudf.from_cudf(X_train, npartitions=n_workers)\n",
    "    X_valid_dask = dask_cudf.from_cudf(X_valid, npartitions=2)\n",
    "    \n",
    "    y_train_dask = dask_cudf.from_cudf(y_train, npartitions=2)\n",
    "    y_valid_dask = dask_cudf.from_cudf(y_valid, npartitions=2)\n",
    "    \n",
    "    X_train_dask, X_valid_dask, y_train_dask, y_valid_dask = dask_utils.persist_across_workers(c, [X_train_dask, X_valid_dask,\n",
    "                                                                      y_train_dask, y_valid_dask], workers=workers)\n",
    "    \n",
    "    classifier.fit(X_train_dask, y_train_dask)\n",
    "    y_pred = classifier.predict(X_valid_dask)\n",
    "    score = accuracy_score(y_valid, y_pred.compute())\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-24 16:24:19,997] A new study created with name: Multi-GPU-Estimator\n",
      "[I 2020-06-24 16:24:24,672] Finished trial#0 with value: 0.8307098150253296 with parameters: {'max_depth': 6, 'n_estimators': 360}. Best is trial#0 with value: 0.8307098150253296.\n",
      "[I 2020-06-24 16:24:27,800] Finished trial#1 with value: 0.8308072090148926 with parameters: {'max_depth': 6, 'n_estimators': 142}. Best is trial#1 with value: 0.8308072090148926.\n",
      "[I 2020-06-24 16:24:31,354] Finished trial#2 with value: 0.8309339880943298 with parameters: {'max_depth': 6, 'n_estimators': 201}. Best is trial#2 with value: 0.8309339880943298.\n",
      "[I 2020-06-24 16:24:34,491] Finished trial#3 with value: 0.8307362198829651 with parameters: {'max_depth': 7, 'n_estimators': 121}. Best is trial#2 with value: 0.8309339880943298.\n",
      "[I 2020-06-24 16:24:37,573] Finished trial#4 with value: 0.8308448195457458 with parameters: {'max_depth': 6, 'n_estimators': 139}. Best is trial#2 with value: 0.8309339880943298.\n",
      "[I 2020-06-24 16:24:40,366] Finished trial#5 with value: 0.8309419751167297 with parameters: {'max_depth': 5, 'n_estimators': 108}. Best is trial#5 with value: 0.8309419751167297.\n",
      "[I 2020-06-24 16:24:44,293] Finished trial#6 with value: 0.8306863903999329 with parameters: {'max_depth': 7, 'n_estimators': 226}. Best is trial#5 with value: 0.8309419751167297.\n",
      "[I 2020-06-24 16:24:47,294] Finished trial#7 with value: 0.8308324217796326 with parameters: {'max_depth': 5, 'n_estimators': 138}. Best is trial#5 with value: 0.8309419751167297.\n",
      "[I 2020-06-24 16:24:51,672] Finished trial#8 with value: 0.8307514190673828 with parameters: {'max_depth': 7, 'n_estimators': 286}. Best is trial#5 with value: 0.8309419751167297.\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "[I 2020-06-24 16:24:55,916] Finished trial#9 with value: 0.8306112289428711 with parameters: {'max_depth': 6, 'n_estimators': 293}. Best is trial#5 with value: 0.8309419751167297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..multi-GPU-estimators    :   35.9608\n"
     ]
    }
   ],
   "source": [
    "with timed(\"multi-GPU-estimators\"):\n",
    "    study = optuna.create_study(sampler= optuna.samplers.TPESampler(),\n",
    "                                study_name=\"Multi-GPU-Estimator\",\n",
    "                                direction=\"maximize\",\n",
    "                                storage=\"sqlite:///mnmg.db\")\n",
    "    study.optimize(objective_mg, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  10\n",
      "Best trial:\n",
      "  Value:  0.8309419751167297\n",
      "  Params: \n",
      "    max_depth: 5\n",
      "    n_estimators: 108\n"
     ]
    }
   ],
   "source": [
    "print_results(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the timing results\n",
    "\n",
    "| Study name | Runtime |   \n",
    "|---|---|\n",
    "| Optuna-Multi-GPU-TPE | 91.3055 |\n",
    "| Optuna-Multi-GPU-CMAE | 88.3086 |\n",
    "| No-Optuna-Call | 89.2947 |\n",
    "| Optuna-MLflow-callback | 88.1154 |\n",
    "| Multi-GPU-Estimator | 35.9608 |\n",
    "\n",
    "We noteice that with 2 GPUS, we were able to run the multi-GPU estimator more than twice as fast as the other options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CPU with 750 estimators max does not finish running after hours.\n",
    "# def objective_cpu(trial):\n",
    "    \n",
    "#     max_depth = trial.suggest_int(\"max_depth\", 5, 15)\n",
    "#     n_estimators = trial.suggest_int(\"n_estimators\", 100, 750)\n",
    "\n",
    "#     classifier = sklearn.ensemble.RandomForestRegressor(max_depth=max_depth,\n",
    "#                                        n_estimators=n_estimators)\n",
    "\n",
    "#     X_train, X_valid, y_train, y_valid = sklearn.model_selection.train_test_split(X_, y_)\n",
    "    \n",
    "#     classifier.fit(X_train, y_train)\n",
    "#     y_pred = classifier.predict(X_valid)\n",
    "    \n",
    "#     score = accuracy_score(y_valid, y_pred)\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with timed(\"cpu-etl\"):\n",
    "#     df_pd = pd.read_parquet(INPUT_FILE)\n",
    "#     X_, y_ = df_pd.drop([\"ArrDelayBinary\"], axis=1), df_pd[\"ArrDelayBinary\"].astype('int32')\n",
    "    \n",
    "# with timed(\"cpu-hpo\"):\n",
    "#     study = optuna.create_study(direction=\"maximize\") # Equivalent to an experiment, a set of trials\n",
    "#     study.optimize(objective_cpu, n_trials=N_TRIALS, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
