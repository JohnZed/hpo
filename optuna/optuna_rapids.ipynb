{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Optuna + RAPIDS\n",
    "\n",
    "Optuna is a lightweight framework for hyperparameter optimization. It provides a code-by-run method which makes it easy to adapt to any already existing code that we have. Just wrapping the objective function with Optuna can help perform a parallel-distributed HPO search over a search space.\n",
    "\n",
    "We'll explore how to use Optuna with RAPIDS and run multi-GPU HPO runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.6/site-packages/treelite/gallery/__init__.py:7: FutureWarning: treelite.gallery.sklearn has been moved to treelite.sklearn. treelite.gallery.sklearn will be removed in version 1.1.\n",
      "  FutureWarning)\n",
      "/opt/conda/envs/rapids/lib/python3.6/site-packages/treelite/gallery/sklearn/__init__.py:9: FutureWarning: treelite.gallery.sklearn has been moved to treelite.sklearn. treelite.gallery.sklearn will be removed in version 1.1.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import dask.array as da\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import cuml\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "from cuml.metrics import accuracy_score\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import time\n",
    "\n",
    "@contextmanager\n",
    "def timed(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    t1 = time.time()\n",
    "    print(\"..%-24s:  %8.4f\" % (name, t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 10\n",
    "INPUT_FILE = \"/home/hyperopt/hyperopt/data/air_par.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.17.0.2:46421</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.17.0.2:8002/status' target='_blank'>http://172.17.0.2:8002/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>49.16 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.17.0.2:46421' processes=2 threads=2, memory=49.16 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "from cuml.dask.common import utils as dask_utils\n",
    "\n",
    "# This will use all GPUs on the local host by default\n",
    "cluster = LocalCUDACluster(threads_per_worker=1, ip=\"\", dashboard_address=\"8002\")\n",
    "c = Client(cluster)\n",
    "\n",
    "# Query the client for all connected workers\n",
    "workers = c.has_what().keys()\n",
    "n_workers = len(workers)\n",
    "n_streams = 8 # Performance optimization\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_parquet(INPUT_FILE)\n",
    "X, y = df.drop([\"ArrDelayBinary\"], axis=1), df[\"ArrDelayBinary\"].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(study):\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the objective Function\n",
    "\n",
    "We will define a objective function for the RandomForestClassifier that searches for max_depth and n_estimators.\n",
    "\n",
    "This will remain constant over different samplers. Samplers are built-in options in Optuna to enable the selection of different sampling algorithms that optuna provides. Some of the available ones include - GridSampler, RandomSampler, TPESampler, etc. We'll try out different samplers and compare their performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(max_depth, n_estimators):\n",
    "    classifier = RandomForestClassifier(max_depth=max_depth,\n",
    "                         n_estimators=n_estimators)\n",
    "\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_valid)\n",
    "    score = accuracy_score(y_valid, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 7)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n",
    "    score = train_and_eval(max_depth=max_depth, n_estimators=n_estimators)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_study(sampler=optuna.samplers.TPESampler(), study_name=\"Optuna-MultiGPU\"):\n",
    "    with timed(\"multi-gpu\"):\n",
    "        study = optuna.create_study(sampler=sampler,\n",
    "                                    study_name=study_name,\n",
    "                                    storage=\"sqlite:///optuna_mg_db.db\",\n",
    "                                    direction=\"maximize\",\n",
    "                                    load_if_exists=True)\n",
    "        with parallel_backend(\"dask\", n_jobs=n_workers, client=c):\n",
    "            study.optimize(objective, n_trials=N_TRIALS, n_jobs=n_workers)\n",
    "    print_results(study)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-30 16:17:28,355] A new study created with name: Optuna-MultiGPU-TPE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..multi-gpu               :   87.3622\n",
      "Number of finished trials:  10\n",
      "Best trial:\n",
      "  Value:  0.8313915729522705\n",
      "  Params: \n",
      "    max_depth: 7\n",
      "    n_estimators: 304\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import performance_report, get_task_stream\n",
    "with get_task_stream(plot='save', filename=\"task-stream.html\") as ts:\n",
    "    study_tpe = run_study(optuna.samplers.TPESampler(),study_name=\"Optuna-MultiGPU-TPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-30 16:23:24,600] Using an existing study with name 'Optuna-MultiGPU-TPE' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..multi-gpu               :   94.5803\n",
      "Number of finished trials:  20\n",
      "Best trial:\n",
      "  Value:  0.8315507769584656\n",
      "  Params: \n",
      "    max_depth: 7\n",
      "    n_estimators: 305\n"
     ]
    }
   ],
   "source": [
    "with performance_report(filename=\"dask-report.html\"):\n",
    "    study_tpe = run_study(optuna.samplers.TPESampler(),study_name=\"Optuna-MultiGPU-TPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.profile(filename=\"dask-profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_cmae = run_study(optuna.samplers.CmaEsSampler(), study_name=\"Optuna-MultiGPU-CMAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential calls without Optuna\n",
    "\n",
    "For a comparison let's try sequential calls without Optuna and it's parallel-processing support. We can cleared see that it takes more time to do this. We'll pick the same parameters as Optuna for a fair comparison - these parameters were selected by the sampling algorithm used by Optuna and is available in the `study.trials_dataframe()` for us to pick out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = study_tpe.trials_dataframe()\n",
    "params_max_depth, params_n_estimators = df['params_max_depth'], df['params_n_estimators']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential call function \n",
    "\n",
    "For a cleaner look, let's use a function to perform sequential calls. The function basically sets the parameters to what was passed and trains and evaluates the model and returns the details of the run which can later be used to find the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_call(max_depth, n_estimators):\n",
    "    classifier = RandomForestClassifier(max_depth=max_depth, n_estimators = n_estimators)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_valid)\n",
    "    score = accuracy_score(y_valid, y_pred)\n",
    "    return score, max_depth, n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "with timed(\"no-optuna-call\"):\n",
    "    with parallel_backend(\"dask\"):\n",
    "        results = Parallel()(delayed(seq_call)(max_depth=params_max_depth[i],\n",
    "                     n_estimators=params_n_estimators[i]) for i in range(N_TRIALS))\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Running this without a dask backend is actually faster - takes about 65 seconds to finish by just making N_TRIALS sequential calls. Dask backend makes most sense when used with multi-GPU estimators as we see later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timed(\"no-optuna-no-dask\"):\n",
    "    for i in range(N_TRIALS):\n",
    "        results = seq_call(max_depth=params_max_depth[i],\n",
    "                     n_estimators=params_n_estimators[i])\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow callback\n",
    "\n",
    "Optuna supports the integration of various libraries. One of them is a tracking library MLflow, this is used to keep track of the different Hyperopt runs. We can simply add it by adding a callback to a study as shown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_callback(study, trial):\n",
    "    trial_value = trial.value if trial.value is not None else float(\"nan\")\n",
    "    with mlflow.start_run(run_name=study.study_name):\n",
    "        print(trial.params)\n",
    "        mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\"accuracy\": trial_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with timed(\"mlflow-callback\"):\n",
    "#     study = optuna.create_study(study_name=\"Optuna-MLflow-callbacsk\",\n",
    "#                                 storage=\"sqlite:///optuna_mlflow_4db.db\",\n",
    "#                                 direction=\"maximize\",\n",
    "#                                 load_if_exists=True)\n",
    "#     with parallel_backend(\"dask\", n_jobs=n_workers):\n",
    "#         study.optimize(objective, n_trials=N_TRIALS, n_jobs=n_workers, timeout=600, callbacks=[mlflow_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU estimators\n",
    "\n",
    "We also have estimators that can run on multiple GPUs. `cuml.dask` has a set of multi-GPU estimators that can run incredibly fast. Let's try that out. In order to do this, we need to used `dask_cudf` dataframes and we will redefine the objective function from earlier to do just that. \n",
    "\n",
    "`objective_mg` converts our split data into dask_cudf dataframes and persists them across all available dask workers. By doing this, we can now run the multi-GPU RandomForestClassifier. Notice that we import the `cuml.dask.ensemble.RandomForestClassifier` for this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.ensemble import RandomForestClassifier as dask_RF\n",
    "\n",
    "def objective_mg(trial):\n",
    "    # Please write actual objective function here.\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 7)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n",
    "\n",
    "    import dask_cudf \n",
    "    \n",
    "    classifier = dask_RF(max_depth=max_depth,\n",
    "                         n_estimators=n_estimators)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "\n",
    "    X_train_dask = dask_cudf.from_cudf(X_train, npartitions=n_workers)\n",
    "    X_valid_dask = dask_cudf.from_cudf(X_valid, npartitions=2)\n",
    "    \n",
    "    y_train_dask = dask_cudf.from_cudf(y_train, npartitions=2)\n",
    "    y_valid_dask = dask_cudf.from_cudf(y_valid, npartitions=2)\n",
    "    \n",
    "    X_train_dask, X_valid_dask, y_train_dask, y_valid_dask = dask_utils.persist_across_workers(c, [X_train_dask, X_valid_dask,\n",
    "                                                                      y_train_dask, y_valid_dask], workers=workers)\n",
    "    \n",
    "    classifier.fit(X_train_dask, y_train_dask)\n",
    "    y_pred = classifier.predict(X_valid_dask)\n",
    "    score = accuracy_score(y_valid, y_pred.compute())\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timed(\"multi-GPU-estimators\"):\n",
    "    study = optuna.create_study(sampler= optuna.samplers.TPESampler(),\n",
    "                                study_name=\"Multi-GPU-Estidsafsmator\",\n",
    "                                direction=\"maximize\",\n",
    "                                storage=\"sqlite:///mnmg.db\")\n",
    "    study.optimize(objective_mg, n_trials=N_TRIALS, n_jobs = n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timed(\"multi-GPU-estimators\"):\n",
    "    with parallel_backend(\"dask\", n_jobs=n_workers):\n",
    "        study = optuna.create_study(sampler= optuna.samplers.TPESampler(),\n",
    "                                    study_name=\"Multi-GPU-Estisdfadmator\",\n",
    "                                    direction=\"maximize\",\n",
    "                                    storage=\"sqlite:///mnmg.db\")\n",
    "        study.optimize(objective_mg, n_trials=N_TRIALS, n_jobs = n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timed(\"multi-GPU-estimators\"):\n",
    "    with parallel_backend(\"dask\", n_jobs=n_workers):\n",
    "        study = optuna.create_study(sampler= optuna.samplers.TPESampler(),\n",
    "                                    study_name=\"Multi-GPrgsdU-Estimator\",\n",
    "                                    direction=\"maximize\",\n",
    "                                    storage=\"sqlite:///mnmg.db\")\n",
    "        study.optimize(objective_mg, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the timing results\n",
    "\n",
    "| Study name | Runtime |   \n",
    "|---|---|\n",
    "| Optuna-Multi-GPU-TPE | 91.3055 |\n",
    "| Optuna-Multi-GPU-CMAE | 88.3086 |\n",
    "| No-Optuna-Call | 89.2947 |\n",
    "| Optuna-MLflow-callback | 88.1154 |\n",
    "| Multi-GPU-Estimator | 35.9608 |\n",
    "\n",
    "We noteice that with 2 GPUS, we were able to run the multi-GPU estimator more than twice as fast as the other options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CPU with 750 estimators max does not finish running after hours.\n",
    "# def objective_cpu(trial):\n",
    "    \n",
    "#     max_depth = trial.suggest_int(\"max_depth\", 5, 15)\n",
    "#     n_estimators = trial.suggest_int(\"n_estimators\", 100, 750)\n",
    "\n",
    "#     classifier = sklearn.ensemble.RandomForestRegressor(max_depth=max_depth,\n",
    "#                                        n_estimators=n_estimators)\n",
    "\n",
    "#     X_train, X_valid, y_train, y_valid = sklearn.model_selection.train_test_split(X_, y_)\n",
    "    \n",
    "#     classifier.fit(X_train, y_train)\n",
    "#     y_pred = classifier.predict(X_valid)\n",
    "    \n",
    "#     score = accuracy_score(y_valid, y_pred)\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with timed(\"cpu-etl\"):\n",
    "#     df_pd = pd.read_parquet(INPUT_FILE)\n",
    "#     X_, y_ = df_pd.drop([\"ArrDelayBinary\"], axis=1), df_pd[\"ArrDelayBinary\"].astype('int32')\n",
    "    \n",
    "# with timed(\"cpu-hpo\"):\n",
    "#     study = optuna.create_study(direction=\"maximize\") # Equivalent to an experiment, a set of trials\n",
    "#     study.optimize(objective_cpu, n_trials=N_TRIALS, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
